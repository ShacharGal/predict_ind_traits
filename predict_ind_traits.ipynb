{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.model_selection import LeaveOneOut, KFold, LeaveOneOut, train_test_split\n",
    "from sklearn.linear_model import LinearRegression, ElasticNetCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score\n",
    "import scipy as sp\n",
    "from scipy.stats import pearsonr\n",
    "pd.options.mode.chained_assignment = None\n",
    "from IPython.core.debugger import set_trace\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import nibabel as nib\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some functions used later in the main functions\n",
    "# or are helpers for reading and handling data\n",
    "\n",
    "def match_dfs_by_ind(df_list, behav, to_compare=[]):\n",
    "    # if we dont have the same subjects available for all tasks, it matches it\n",
    "    all_indices = [list(df.index) for df in df_list]\n",
    "    all_indices.append(behav.index)\n",
    "    if len(to_compare):\n",
    "        all_indices.append(to_compare.index)\n",
    "    in_all = list(set(all_indices[0]).intersection(*all_indices))\n",
    "    return [df[df.index.isin(in_all)] for df in df_list], behav[behav.index.isin(in_all)]\n",
    "    \n",
    "def read_features(to_use, subjlist='test_subjlist', to_scale=True):\n",
    "    orig_mat = np.genfromtxt(f'data/{to_use}.csv', delimiter=',')\n",
    "    subjects_path = f'data/{subjlist}.txt'\n",
    "    with open(subjects_path, 'r') as f:\n",
    "        subjects = [line.rstrip('\\n') for line in f]\n",
    "\n",
    "    # arrange features in df and keep only subjects that we have g scores for\n",
    "    features = pd.DataFrame(data=orig_mat, index=subjects)\n",
    "    \n",
    "    if to_scale:\n",
    "        # scale features\n",
    "        scaler = StandardScaler()\n",
    "        scaled_features = pd.DataFrame(data = scaler.fit_transform(features), index = features.index)\n",
    "        \n",
    "        return scaled_features\n",
    "    else:\n",
    "        return features\n",
    "\n",
    "def decompose(data, num_comps, transformer='pca'):\n",
    "    # recieves a subjectsXvertices matrix. returns verticesXcomponents matrix\n",
    "    if transformer == 'pca':\n",
    "        trans = PCA()\n",
    "    if transformer == 'ica':\n",
    "        trans = FastICA(max_iter=500)\n",
    "    trans.fit(data)\n",
    "    return trans.components_.T[:,:num_comps]\n",
    "\n",
    "def demean_by_train(train, test):\n",
    "    # demeans the data by the training sets mean\n",
    "\n",
    "    train_avg = train.mean(axis=0)\n",
    "    train_demeaned = train-train_avg\n",
    "    test_demeaned = test-train_avg\n",
    "    return train_demeaned, test_demeaned\n",
    "\n",
    "def shuffle_copy(to_shuffle):\n",
    "    # returns shuffled DataFrame to utilize in permutation tests\n",
    "    \n",
    "    shuffled = to_shuffle.copy()\n",
    "    shuffled = shuffled.values\n",
    "    np.random.shuffle(shuffled)\n",
    "    return shuffled\n",
    "\n",
    "\n",
    "def corr_analysis(features, y, ff_num):\n",
    "    # select featrues cpm-style\n",
    "    feat_num = features.shape[1]\n",
    "    corrs = np.zeros(feat_num)\n",
    "    for feat in range(feat_num):\n",
    "        corrs[feat] = sp.stats.pearsonr(features[:,feat],y)[0]\n",
    "    mask = abs(corrs)>=np.sort(abs(corrs))[len(corrs)-ff_num]\n",
    "    return mask\n",
    "\n",
    "def save_masked_maps(data, filename):\n",
    "    template = nib.load('data/Smask.dtseries.nii')\n",
    "    mask = np.asanyarray(template.dataobj)\n",
    "    mask[mask==1]=data\n",
    "    to_save = nib.cifti2.cifti2.Cifti2Image(mask, template.header)\n",
    "    nib.save(to_save, f'{filename}.dtseries.nii')\n",
    "    \n",
    "def get_task_feat_num(mask, num_comps):\n",
    "    num_tasks = len(mask)/num_comps\n",
    "    f_per_task = []\n",
    "    for task in range(int(num_tasks)):\n",
    "        f_per_task.append((mask[num_comps*task: num_comps*(task+1)].sum()))\n",
    "    return f_per_task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# two functions - one for single data entry and one for multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_bbs_single(features, score_df, k=10, num_comps=75, score='g_efa', return_stats=True, save_maps=False):\n",
    "    \n",
    "    stats = {'r':[], 'mse':[]}\n",
    "    \n",
    "    kfold = KFold(n_splits=k, random_state=42, shuffle=True)\n",
    "    predicted = np.zeros(features.shape[0])\n",
    "            \n",
    "    consensus = np.zeros((features.shape[1]))\n",
    "    \n",
    "    for fold, (train_index, test_index) in enumerate(kfold.split(features)):\n",
    "        print(f'fold {fold+1} out of {k}')\n",
    "        train_features = np.zeros([len(train_index),num_comps])\n",
    "        test_features = np.zeros([len(test_index),num_comps])\n",
    "        \n",
    "        X_train, X_test = features.iloc[train_index,:], features.iloc[test_index,:]\n",
    "        Y_train, Y_test = score_df[score].iloc[train_index], score_df[score].iloc[test_index]\n",
    "        # create pca-reduced matrix, in the shpae of verticesXcomponents\n",
    "        reduced_train = decompose(X_train, num_comps, transformer='pca')\n",
    "\n",
    "        # extract individual features by calculating expression scores for each subject\n",
    "        train_features = np.matmul(np.linalg.pinv(reduced_train),X_train.values.T).T            \n",
    "        test_features = np.matmul(np.linalg.pinv(reduced_train),X_test.values.T).T\n",
    "\n",
    "\n",
    "        \n",
    "        # calculate model and get predictions\n",
    "        model = LinearRegression()\n",
    "        model.fit(train_features, Y_train)            \n",
    "        predicted[test_index] = model.predict(test_features)\n",
    "        \n",
    "        if return_stats:\n",
    "            stats['r'].append(sp.stats.pearsonr(predicted[test_index], Y_test)[0])\n",
    "            stats['mse'].append(mean_squared_error(predicted[test_index], Y_test))\n",
    "        \n",
    "        if save_maps:\n",
    "            # weight components with their related beta values\n",
    "            weighted_task_comps = reduced_train*model.coef_\n",
    "            # sum over components to get a single weighted map for this fold\n",
    "            summed_weighted_task_comps = np.sum(weighted_task_comps,axis=1)\n",
    "            # add the weighted components to the rest of the weighted components.\n",
    "            consensus += summed_weighted_task_comps\n",
    "        \n",
    "    if return_stats:\n",
    "        summary = pd.DataFrame(stats).describe().loc[['mean', 'std'],:]\n",
    "        if save_maps:\n",
    "            return predicted, stats, summary, consensus\n",
    "        else:\n",
    "            return predicted, stats, summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_bbs_multi_data_select(dfs_list, score_df, reg_type, k=10, num_comps=75, score='g_efa', ff_num = 75, l1_ratio=0.01, save_maps=False):\n",
    "    \n",
    "    stats = {'r':[], 'mse':[]}\n",
    "\n",
    "    kfold = KFold(n_splits=k, random_state=42, shuffle=True)\n",
    "    feature_example = dfs_list[0]\n",
    "    predicted = np.zeros(feature_example.shape[0])\n",
    "    \n",
    "    task_comps_per_fold = []                     \n",
    "    consensus = np.zeros((feature_example.shape[1]))\n",
    "    \n",
    "    for fold, (train_index, test_index) in enumerate(kfold.split(feature_example)):\n",
    "        print(f'fold {fold+1} out of {k}')\n",
    "        train_features = np.zeros([len(train_index),num_comps*len(dfs_list)])\n",
    "        test_features = np.zeros([len(test_index),num_comps*len(dfs_list)])\n",
    "        # define this folds' Y\n",
    "        Y_train, Y_test = score_df[score].iloc[train_index], score_df[score].iloc[test_index]\n",
    "\n",
    "        fold_comps = np.zeros((feature_example.shape[1], num_comps*len(dfs_list)))\n",
    "\n",
    "        for i in range(len(dfs_list)):\n",
    "            features = dfs_list[i]\n",
    "            X_train, X_test = features.iloc[train_index,:], features.iloc[test_index,:]\n",
    "\n",
    "            # create pca-reduced matrix, in the shpae of verticesXcomponents\n",
    "            reduced_train = decompose(X_train, num_comps, transformer='pca')\n",
    "\n",
    "            # extract individual features by calculating expression scores for each subject\n",
    "            this_train_features = np.matmul(np.linalg.pinv(reduced_train),X_train.values.T).T            \n",
    "            this_test_features = np.matmul(np.linalg.pinv(reduced_train),X_test.values.T).T\n",
    "            \n",
    "            start = i*num_comps\n",
    "            end = start+num_comps\n",
    "            train_features[:, start:end] = this_train_features\n",
    "            test_features[:, start:end] = this_test_features\n",
    "            \n",
    "            # save the components used for feature extration \n",
    "            if save_maps: \n",
    "                fold_comps[:,start:end] = reduced_train\n",
    "        \n",
    "\n",
    "        # correlation analysis to select features\n",
    "        mask = corr_analysis(train_features, Y_train, ff_num)\n",
    "        task_comps_per_fold.append(get_task_feat_num(mask, num_comps))\n",
    "        \n",
    "        # reduce features with mask produced in the correlation analysis\n",
    "        train_features = train_features[:, mask]\n",
    "        test_features = test_features[:, mask]\n",
    "        \n",
    "        # calculate model and get predictions\n",
    "        if reg_type == 'glm':\n",
    "            model = LinearRegression()\n",
    "        elif reg_type == 'elnet':\n",
    "            model = ElasticNetCV(l1_ratio=l1_ratio,n_alphas=50, tol=0.001, max_iter=5000)\n",
    "            \n",
    "        model.fit(train_features, Y_train)\n",
    "        betas = model.coef_\n",
    "                    \n",
    "        predicted[test_index] = model.predict(test_features)\n",
    "        \n",
    "        stats['r'].append(sp.stats.pearsonr(predicted[test_index], Y_test)[0])\n",
    "        stats['mse'].append(mean_squared_error(predicted[test_index], Y_test))\n",
    "\n",
    "        if save_maps:\n",
    "            #reduce fold_comps according to the correlation analysis\n",
    "            masked_comps = fold_comps[:,mask]\n",
    "            # weight components with their related beta values\n",
    "            weighted_task_comps = masked_comps*betas\n",
    "            # sum over components to get a single weighted map for this fold\n",
    "            summed_weighted_task_comps = np.sum(weighted_task_comps,axis=1)\n",
    "            # add the weighted components to the rest of the weighted components.\n",
    "            consensus += summed_weighted_task_comps\n",
    "        \n",
    "    summary = pd.DataFrame(stats).describe().loc[['mean', 'std'],:]\n",
    "    if save_maps:\n",
    "        return predicted, stats, summary, consensus\n",
    "    else:\n",
    "        return predicted, stats, summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# examples for how to read in data and run predictions\n",
    "\n",
    "unfortunately, we cannot upload example data, due to the HCP's terms of conditions.\n",
    "here we explain how to arange your data and provide the examples for using it with the code in this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the behavioural data, keep only needed columns\n",
    "hcp_df = pd.read_csv('hcp_dataframe_with_g.csv')\n",
    "hcp_df['Subject'] = hcp_df['Subject'].apply(str) \n",
    "hcp_df = hcp_df.set_index('Subject')\n",
    "\n",
    "hcp_df = hcp_df[['PMAT24_A_CR', 'ReadEng_Unadj', 'g_efa', 'NEOFAC_O', 'NEOFAC_C', 'NEOFAC_E', 'NEOFAC_A', 'NEOFAC_N']]\n",
    "hcp_df = hcp_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examples for reading in data\n",
    "subjlist='example_data/test_subjlist'\n",
    "\n",
    "# here we read in the connectome data - for each subject, a vector of 64620 connectome edges\n",
    "# created using HCP's Multi Modal Parcellation - https://www.nature.com/articles/nature18933\n",
    "rs_conn = read_features('example_data/rs_conn',subjlist=subjlist)\n",
    "# now, read in some task/connTask data\n",
    "# the data is masked to only include cortex, and aranged such that each subject's map is a row\n",
    "wm_2bk_orig_z = read_features('example_data/WM_09_s4_z_masked_orig', subjlist=subjlist, to_scale=True)\n",
    "wm_2bk_pred_z = read_features('example_data/WM_09_s4_z_masked_pred', subjlist=subjlist, to_scale=True)\n",
    "lang_mathstory_pred_z= read_features('example_data/Lang_03_s4_z_masked_pred', subjlist=subjlist, to_scale=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1 out of 10\n",
      "fold 2 out of 10\n",
      "fold 3 out of 10\n",
      "fold 4 out of 10\n",
      "fold 5 out of 10\n",
      "fold 6 out of 10\n",
      "fold 7 out of 10\n",
      "fold 8 out of 10\n",
      "fold 9 out of 10\n",
      "fold 10 out of 10\n",
      "             r       mse\n",
      "mean  0.536538  0.523136\n",
      "std   0.064327  0.082836\n",
      "fold 1 out of 10\n",
      "fold 2 out of 10\n",
      "fold 3 out of 10\n",
      "fold 4 out of 10\n",
      "fold 5 out of 10\n",
      "fold 6 out of 10\n",
      "fold 7 out of 10\n",
      "fold 8 out of 10\n",
      "fold 9 out of 10\n",
      "fold 10 out of 10\n",
      "             r       mse\n",
      "mean  0.425718  0.602067\n",
      "std   0.081653  0.126863\n"
     ]
    }
   ],
   "source": [
    "# to run a prediction, we first make sure that the behavioral data includes only the subjects in the image data\n",
    "dfs, behav = match_dfs_by_ind([wm_2bk_orig_z], hcp_df)\n",
    "predicted, stats, summary = do_bbs_single(dfs[0], behav)\n",
    "print(summary)\n",
    "\n",
    "dfs, behav = match_dfs_by_ind([wm_2bk_pred_z], hcp_df)\n",
    "predicted, stats, summary = do_bbs_single(dfs[0], behav)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1 out of 10\n",
      "fold 2 out of 10\n",
      "fold 3 out of 10\n",
      "fold 4 out of 10\n",
      "fold 5 out of 10\n",
      "fold 6 out of 10\n",
      "fold 7 out of 10\n",
      "fold 8 out of 10\n",
      "fold 9 out of 10\n",
      "fold 10 out of 10\n",
      "             r       mse\n",
      "mean  0.444150  0.594766\n",
      "std   0.070218  0.124929\n"
     ]
    }
   ],
   "source": [
    "# now predict using multi data. heres an example on how to do os using 2 images\n",
    "dfs, behav = match_dfs_by_ind([wm_2bk_pred_z, lang_mathstory_pred_z], hcp_df)\n",
    "predicted, stats, summary = do_bbs_multi_data_select(dfs, behav, reg_type='elnet')\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check significance of comparison between inputs\n",
    "\n",
    "here we prform significance testing by creating 30 different train-test splits, and on each such split, we perform prediction of a trait, using resting-state connectivity and another different data type with which to compare.\n",
    "we then test for differnces in prediction accuracy using Wilcoxon signed rank test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_predictions_single(A,B,hcp_df,score,k=30, num_comps=75):\n",
    "    dfs, behav = match_dfs_by_ind([A,B], hcp_df)\n",
    "    \n",
    "    score_dict = {0:[], 1:[]}\n",
    "    for i in range(k):\n",
    "        if i%10==0:\n",
    "            print(f'iteration {i} out of {k}')\n",
    "            \n",
    "        rand_seed = np.random.randint(0,1000)\n",
    "        for m in [0,1]:\n",
    "            \n",
    "            X_train, X_test, y_train, y_test = train_test_split(dfs[m], behav[score], test_size=0.33, random_state=rand_seed)\n",
    "            reduced_train = decompose(X_train, num_comps, transformer='pca')\n",
    "\n",
    "            # extract individual features by calculating expression scores for each subject\n",
    "            train_features = np.matmul(np.linalg.pinv(reduced_train),X_train.values.T).T            \n",
    "            test_features = np.matmul(np.linalg.pinv(reduced_train),X_test.values.T).T\n",
    "            model = LinearRegression()\n",
    "            model.fit(train_features, y_train)\n",
    "            predicted = model.predict(test_features)\n",
    "            r = pearsonr(predicted,y_test)[0]\n",
    "            score_dict[m].append(r)\n",
    "            \n",
    "    s,p = sp.stats.wilcoxon(score_dict[0], score_dict[1], alternative='greater')\n",
    "    return s,p\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 out of 30\n",
      "iteration 10 out of 30\n",
      "iteration 20 out of 30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(465.0, 8.666533220995528e-07)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_predictions_single(wm_2bk_pred_z, rs_conn, hcp_df, 'g_efa', k=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get data of mean activity in DMN and FPN\n",
    "\n",
    "this is the code by which we extracted mean activations in DMN and FPN for original and predicted maps, for the analysis presented in figure 3 of the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrasts = {'2bk>0bk' : 'WM_11_s4', '2bk': 'WM_09_s4', '0bk': 'WM_10_s4',\n",
    "        'Math-Story' : 'Lang_03_s4',\n",
    "        'Random' : 'Soc_01_s4', 'TOM': 'Soc_02_s4', 'TOM-Radnom': 'Soc_06_s4',\n",
    "        'Rel' : 'Rel_02_s4', 'Match': 'Rel_01_s4', 'Rel-Match': 'Rel_04_s4',\n",
    "        'Reweard': 'Gamb_02_s4', 'Punish': 'Gamb_01_s4', 'Punish-Reward': 'Gamb_03_s4',\n",
    "        'Faces-Shapes': 'Em_03_s4'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yeo_parc = nib.load('/Volumes/HCP/HCP_WB_Tutorial_1.0/yeo_masked.dtseries.nii')\n",
    "yeo_parc = np.asanyarray(yeo_parc.dataobj)\n",
    "fpn_num = 6;\n",
    "dmn_num = 7;\n",
    "fpn_mask = (yeo_parc==fpn_num).flatten()\n",
    "dmn_mask = (yeo_parc==dmn_num).flatten()\n",
    "\n",
    "data_dir = '/Volumes/HCP/Predicted_data_100';\n",
    "\n",
    "orig_fpn_mean=[]\n",
    "orig_dmn_mean=[]\n",
    "pred_fpn_mean=[]\n",
    "pred_dmn_mean=[]\n",
    "contrast_description = list(contrasts.keys())\n",
    "contrast_names = list(contrasts.values())\n",
    "\n",
    "for con in contrast_names:\n",
    "    print(con)\n",
    "    all_orig_path = f'{data_dir}/{con}/all_test_data/all_test_data_orig_z.dtseries.nii'\n",
    "    all_orig = nib.load(all_orig_path)\n",
    "    all_orig = np.asanyarray(all_orig.dataobj)\n",
    "    \n",
    "    orig_fpn_mean.append(np.mean(np.mean(all_orig[:, fpn_mask])));\n",
    "    orig_dmn_mean.append(np.mean(np.mean(all_orig[:, dmn_mask])));\n",
    "    \n",
    "    all_pred_path = f'{data_dir}/{con}/all_test_data/all_test_data_pred_z_cleaned_cb.dtseries.nii'\n",
    "    all_pred = nib.load(all_pred_path)\n",
    "    all_pred = np.asanyarray(all_pred.dataobj)\n",
    "    \n",
    "    pred_fpn_mean.append(np.mean(np.mean(all_pred[:, fpn_mask])));\n",
    "    pred_dmn_mean.append(np.mean(np.mean(all_pred[:, dmn_mask])));\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
